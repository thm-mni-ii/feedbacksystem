# Properties for akka.kafka.ProducerSettings can be
# defined in this section or a configuration section with
# the same layout.

akka {
  # options: OFF, ERROR, WARNING, INFO, DEBUG
  loglevel = "WARNING"
}

akka.kafka.producer {
  # Tuning parameter of how many sends that can run in parallel.
  # parallelism = 100

  # How long to wait for `KafkaProducer.close`
  # close-timeout = 60s

  # Fully qualified config path which holds the dispatcher configuration
  # to be used by the producer stages. Some blocking may occur.
  # When this value is empty, the dispatcher configured for the stream
  # will be used.
  # use-dispatcher = "akka.kafka.default-dispatcher"

  # The time interval to commit a transaction when using the `Transactional.sink` or `Transactional.flow`
  # eos-commit-interval = 100ms

  # Properties defined by org.apache.kafka.clients.producer.ProducerConfig
  # can be defined in this configuration section.
  kafka-clients {
    bootstrap.servers = "kafka1:9092"
  }
}

# Properties for akka.kafka.ConsumerSettings can be
# defined in this section or a configuration section with
# the same layout.
akka.kafka.consumer {
  # Tuning property of scheduled polls.
  # poll-interval = 50ms

  # Tuning property of the `KafkaConsumer.poll` parameter.
  # Note that non-zero value means that the thread that
  # is executing the stage will be blocked.
  # poll-timeout = 50ms

  # The stage will await outstanding offset commit requests before
  # shutting down, but if that takes longer than this timeout it will
  # stop forcefully.
  # stop-timeout = 30s

  # How long to wait for `KafkaConsumer.close`
  # close-timeout = 20s

  # If offset commit requests are not completed within this timeout
  # the returned Future is completed `CommitTimeoutException`.
  # commit-timeout = 15s

  # If commits take longer than this time a warning is logged
  # commit-time-warning = 1s

  # If for any reason `KafkaConsumer.poll` blocks for longer than the configured
  # poll-timeout then it is forcefully woken up with `KafkaConsumer.wakeup`.
  # The KafkaConsumerActor will throw
  # `org.apache.kafka.common.errors.WakeupException` which will be ignored
  # until `max-wakeups` limit gets exceeded.
  # wakeup-timeout = 60s

  # After exceeding maxinum wakeups the consumer will stop and the stage and fail.
  # Setting it to 0 will let it ignore the wakeups and try to get the polling done forever.
  # max-wakeups = 10

  # If set to a finite duration, the consumer will re-send the last committed offsets periodically
  # for all assigned partitions. See https://issues.apache.org/jira/browse/KAFKA-4682.
  # commit-refresh-interval = infinite

  # If enabled, log stack traces before waking up the KafkaConsumer to give
  # some indication why the KafkaConsumer is not honouring the `poll-timeout`
  #wakeup-debug = true

  # Fully qualified config path which holds the dispatcher configuration
  # to be used by the KafkaConsumerActor. Some blocking may occur.
  # use-dispatcher = "akka.kafka.default-dispatcher"

  # Properties defined by org.apache.kafka.clients.consumer.ConsumerConfig
  # can be defined in this configuration section.
  kafka-clients {
    # auto-commit disabled by default
    # Setting enable.auto.commit means that offsets are committed automatically
    #  with a frequency controlled by the config auto.commit.interval.ms.
    enable.auto.commit = true

    bootstrap.servers = "kafka1:9092"
    group.id = "test-group1"

    auto.offset.reset = "earliest"
  }

  # Time to wait for pending requests when a partition is closed
  # wait-close-partition = 500ms
}